{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(['NNCB',\n",
    "\n",
    "                 'CH -> B',\n",
    "                 'HH -> N',\n",
    "                 'CB -> H',\n",
    "                 'NH -> C',\n",
    "                 'HB -> C',\n",
    "                 'HC -> B',\n",
    "                 'HN -> C',\n",
    "                 'NN -> C',\n",
    "                 'BH -> H',\n",
    "                 'NC -> B',\n",
    "                 'NB -> B',\n",
    "                 'BN -> B',\n",
    "                 'BB -> N',\n",
    "                 'BC -> B',\n",
    "                 'CC -> N',\n",
    "                 'CN -> C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(data):\n",
    "    polymer = data[0]\n",
    "    insert = {}\n",
    "    for i in range(1, len(data)):\n",
    "        pair, insr = data[i].split(' -> ')\n",
    "        insert[pair] = insr\n",
    "    return polymer, insert\n",
    "\n",
    "#Brute force\n",
    "def pair_insert(polymer, insert):\n",
    "    new_polymer = ''+polymer[0]\n",
    "    for i in range(0, len(polymer)-1):\n",
    "        pair = polymer[i:i+2]\n",
    "        new_polymer += insert[pair]\n",
    "        new_polymer += pair[-1]\n",
    "    return new_polymer\n",
    "\n",
    "def run_pair_insert(polymer, insert, steps):\n",
    "    for i in range(0, steps):\n",
    "        polymer = pair_insert(polymer, insert)\n",
    "    return polymer\n",
    "\n",
    "def part1(data, steps):\n",
    "    polymer, insert = process_input(data)\n",
    "    polymer = run_pair_insert(polymer, insert, steps)\n",
    "    \n",
    "    polymer = np.array(list(polymer))\n",
    "    unique, count = np.unique(polymer, return_counts=True)\n",
    "    print('max', unique[np.argmax(count)], np.max(count))\n",
    "    print('min', unique[np.argmin(count)], np.min(count))\n",
    "    return np.max(count) - np.min(count)\n",
    "\n",
    "print(part1(test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = np.genfromtxt('day14_input.txt', dtype=str, delimiter='\\n')\n",
    "print('Part 1 Result:', part1(inpt, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute force is not possible (too long, too much memory)\n",
    "\n",
    "def polymer_pairs(polymer):\n",
    "    #Count the occurance of pairs in origional polymer\n",
    "    pair_counts = defaultdict(int)\n",
    "    for i in range(0, len(polymer)-1):\n",
    "        pair = polymer[i:i+2]\n",
    "        pair_counts[pair] += 1\n",
    "        \n",
    "    return pair_counts\n",
    "\n",
    "def pair_insert(pair_counts, insert):\n",
    "    next_pair_counts = defaultdict(int)\n",
    "    \n",
    "    for pair in pair_counts.keys():\n",
    "        #Insert the new character between two existing characters\n",
    "        pair1 = pair[0]+insert[pair]\n",
    "        pair2 = insert[pair]+pair[1]\n",
    "        \n",
    "        #Increment the two new pairs (pair1 and pair2) by\n",
    "        #the number of times \"pair\" existed before\n",
    "        next_pair_counts[pair1] += pair_counts[pair]\n",
    "        next_pair_counts[pair2] += pair_counts[pair]\n",
    "        \n",
    "    return next_pair_counts\n",
    "\n",
    "def count_chars(polymer, pair_counts):\n",
    "    char_counts = defaultdict(int)\n",
    "    \n",
    "    #All caracters will be double counted except the first and last,\n",
    "    #so add those to the counts\n",
    "    char_counts[polymer[0]] += 1\n",
    "    char_counts[polymer[-1]] += 1\n",
    "    \n",
    "    for pair in pair_counts.keys():\n",
    "        #Count the occurance of each character\n",
    "        char_counts[pair[0]] += pair_counts[pair]\n",
    "        char_counts[pair[-1]] += pair_counts[pair]\n",
    "        \n",
    "    return char_counts\n",
    "\n",
    "def expand_polymer(data, steps):\n",
    "    polymer, insert = process_input(data)\n",
    "    pair_counts = polymer_pairs(polymer)\n",
    "    for i in range(0, steps):\n",
    "        pair_counts = pair_insert(pair_counts, insert)\n",
    "    char_counts = count_chars(polymer, pair_counts)\n",
    "    \n",
    "    maxi = np.max(list(char_counts.values()))\n",
    "    mini = np.min(list(char_counts.values()))\n",
    "    \n",
    "    return int((maxi - mini)/2) #we double counted so divide by 2\n",
    "\n",
    "print(expand_polymer(test, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Part 2 Result:', expand_polymer(inpt, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
